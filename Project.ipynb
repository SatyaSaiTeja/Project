{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Not found, Creating a new M\n",
      "Found 180 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satya Karuturi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Satya Karuturi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Satya Karuturi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Satya Karuturi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\Users\\Satya Karuturi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\Users\\Satya Karuturi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 4 classes.\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 357s 357ms/step - loss: 0.9071 - accuracy: 0.6357 - val_loss: 0.5804 - val_accuracy: 0.8389\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 345s 345ms/step - loss: 0.4852 - accuracy: 0.8186 - val_loss: 0.5805 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 353s 353ms/step - loss: 0.4289 - accuracy: 0.8369 - val_loss: 0.4992 - val_accuracy: 0.8611\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 361s 361ms/step - loss: 0.3982 - accuracy: 0.8455 - val_loss: 0.4675 - val_accuracy: 0.8277\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 347s 347ms/step - loss: 0.3700 - accuracy: 0.8589 - val_loss: 0.5112 - val_accuracy: 0.8222\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 283s 283ms/step - loss: 0.3552 - accuracy: 0.8652 - val_loss: 0.5106 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 280s 280ms/step - loss: 0.3400 - accuracy: 0.8725 - val_loss: 0.4487 - val_accuracy: 0.8612\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 270s 270ms/step - loss: 0.3312 - accuracy: 0.8757 - val_loss: 0.3494 - val_accuracy: 0.8889\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.3243 - accuracy: 0.8790 - val_loss: 0.3284 - val_accuracy: 0.8055\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 290s 290ms/step - loss: 0.3133 - accuracy: 0.8833 - val_loss: 0.3481 - val_accuracy: 0.8945\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 274s 274ms/step - loss: 0.3110 - accuracy: 0.8855 - val_loss: 0.3838 - val_accuracy: 0.8944\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.3096 - accuracy: 0.8864 - val_loss: 0.4581 - val_accuracy: 0.8555\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 271s 271ms/step - loss: 0.3052 - accuracy: 0.8886 - val_loss: 0.4293 - val_accuracy: 0.8555\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.3333 - accuracy: 0.8879 - val_loss: 0.4182 - val_accuracy: 0.8778\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.3031 - accuracy: 0.8919 - val_loss: 0.4175 - val_accuracy: 0.8444\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.3026 - accuracy: 0.8942 - val_loss: 0.2944 - val_accuracy: 0.9222\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 293s 293ms/step - loss: 0.3018 - accuracy: 0.8946 - val_loss: 0.5323 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.3097 - accuracy: 0.8944 - val_loss: 0.3734 - val_accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.3126 - accuracy: 0.8919 - val_loss: 0.4078 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 296s 296ms/step - loss: 0.3036 - accuracy: 0.8943 - val_loss: 0.3020 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.3074 - accuracy: 0.8930 - val_loss: 0.3129 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.3000 - accuracy: 0.8960 - val_loss: 0.2611 - val_accuracy: 0.9111\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.3063 - accuracy: 0.8933 - val_loss: 0.4812 - val_accuracy: 0.8445\n",
      "Epoch 24/100\n",
      " 101/1000 [==>...........................] - ETA: 2:13 - loss: 0.2988 - accuracy: 0.88"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "import cv2,numpy as np\n",
    "from keras.models import load_model\n",
    "import glob\n",
    "from keras import optimizers\n",
    "\n",
    "#training set images should be separated as folders of their corres output\n",
    "def create_cnn(model_path=None):\n",
    "    #initialization\n",
    "    classifier=Sequential()\n",
    "    \n",
    "    #Convolution\n",
    "    classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "\n",
    "    #Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #Dropout\n",
    "    classifier.add(Dropout(0.5))\n",
    "    #Adding 2nd conv. layaer\n",
    "    classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(Dropout(0.5))\n",
    "    \n",
    "    classifier.add(Convolution2D(64,3,3,activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    classifier.add(Dropout(0.5))\n",
    "    \n",
    "    #Flattening\n",
    "    classifier.add(Flatten())\n",
    "\n",
    "    #Full Connected Layers\n",
    "    classifier.add(Dense(output_dim=128,activation='relu'))\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(output_dim=128,activation='relu'))\n",
    "    classifier.add(Dropout(0.5))\n",
    "    classifier.add(Dense(output_dim=4,activation='softmax'))\n",
    "\n",
    "    #compliling CNN important to remem loss fun and optimizer\n",
    "    classifier.compile(optimizer=optimizers.RMSprop(lr=0.0004),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    #Fitting CNN to Images\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    training_set = train_datagen.flow_from_directory(\n",
    "        'C:\\\\Users\\\\Satya Karuturi\\\\Documents\\\\GitHub\\\\elpv-dataset\\\\images',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    test_set = test_datagen.flow_from_directory(\n",
    "        'C:\\\\Users\\\\Satya Karuturi\\\\Documents\\\\GitHub\\\\elpv-dataset\\\\images',\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=100,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000)\n",
    "\n",
    "    #saving the model with this name\n",
    "    classifier.save('classifier.h5')\n",
    "    \n",
    "    if model_path:\n",
    "        model=load_model('classifier.h5')\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Opening the image for prediction\n",
    "    file_path='C:\\\\Users\\\\Satya Karuturi\\\\Documents\\\\GitHub\\\\elpv-dataset\\\\Im2\\\\cell0005.png'\n",
    "    im=cv2.resize(cv2.imread(file_path),(64,64)).astype(np.float32)\n",
    "    #cv2.imshow('Sample',cv2.resize(cv2.imread(file_path),(640,480)))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    \n",
    "    #Checking if model is present in the Directory\n",
    "    if(glob.glob('*.h5')):\n",
    "        for filename in glob.glob('*.h5'):\n",
    "            model=load_model(filename)\n",
    "            print('Model Loaded')\n",
    "    else:\n",
    "        print('Model Not found, Creating a new M')\n",
    "        model=create_cnn('classifier.h5')\n",
    "    \n",
    "    #Compiling the model and predicting Output\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=0.0004),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    out=model.predict(im)\n",
    "    \n",
    "    if out[0][0]==1:\n",
    "        prediction='class1'\n",
    "    elif out[0][0]==2:\n",
    "        prediction='Class2'\n",
    "    elif out[0][0]==3:\n",
    "        prediction='Class3'\n",
    "    else:\n",
    "        prediction=='Class4'\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
